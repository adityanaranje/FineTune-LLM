# üìò Fine-Tuning LLMs

## üîç What Is Fine-Tuning?

Fine-tuning is the process of taking a pretrained Large Language Model (LLM) and training it further on a **specific dataset** so it adapts to a domain, task, or writing style.

A pretrained model already understands:
- Language  
- World knowledge  
- Reasoning  
- Grammar  
- Common patterns  

But it may not perfectly handle **your** domain or **your** output structure.  
Fine-tuning adjusts internal weights so the model behaves exactly how you want.

---

## ‚ùì Why Fine-Tune If RAG Already Exists?

**RAG (Retrieval-Augmented Generation)** retrieves external documents and feeds them into the model during inference.  
But RAG does **not** change the model‚Äôs internal behavior.

| Capability | RAG | Fine-Tuning |
|------------|-----|-------------|
| Add external knowledge | ‚úÖ | ‚ùå |
| Teach structure, style, tone | ‚ùå | ‚úÖ |
| Improve reasoning | ‚ö†Ô∏è | ‚úÖ |
| Reduce hallucinations | ‚ö†Ô∏è | ‚ö†Ô∏è |
| Requires vector DB | Yes | No |
| Knowledge stored inside model | No | Yes |
| Output consistency | Low | High |

### RAG is not enough when:
- You need consistent output formats  
- You expect domain-specific reasoning  
- You want internalized rules  
- You want task-specific models  
- You want independence from retrieval pipelines  

### Fine-Tuning + RAG works best when:
- RAG provides **knowledge**  
- Fine-tuning provides **behavior + structure**  

---

# üß© Types of Fine-Tuning

## 1Ô∏è‚É£ **Full Fine-Tuning**

Updates **all** model parameters.

$$
\theta_{\text{new}} = \theta_{\text{old}} - \eta \cdot \nabla_\theta \mathcal{L}(x, y)
$$

---

## 2Ô∏è‚É£ **Parameter-Efficient Fine-Tuning (PEFT)**

Only updates a **small fraction** of weights.

Types:
- LoRA  
- QLoRA  
- Prefix / Prompt Tuning  
- Adapters  

---

# ‚öô LoRA (Low-Rank Adaptation)

\[
W' = W + BA
\]

LoRA injects small trainable matrices into transformer layers instead of modifying full weights.

---

# ‚ö° QLoRA (Quantized LoRA)

\[
W' = D(W_q) + BA
\]

QLoRA quantizes the base model to **4-bit NF4** to drastically reduce memory usage.

---

# üèé LoRA vs QLoRA

| Feature | LoRA | QLoRA |
|---------|------|-------|
| Precision | FP16 | 4-bit |
| Memory | Medium | Very Low |
| GPU | 24GB+ | 8‚Äì12GB |
| Accuracy | High | Near full |

---

# üìê Math Behind Fine-Tuning

$$
\hat{y} = f(x;\theta)
$$

$$
\mathcal{L} = - \sum y \log(\hat{y})
$$

$$
\theta = \theta - \eta \nabla_\theta \mathcal{L}
$$

---

# üßæ Summary

| Problem | Best Method |
|---------|-------------|
| Add knowledge | RAG |
| Improve behavior | Fine-Tuning |
| Low GPU | QLoRA |
| Specialization | LoRA/QLoRA |
